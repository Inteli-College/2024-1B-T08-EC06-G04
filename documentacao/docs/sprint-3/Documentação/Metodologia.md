---
sidebar_position: 1
custom_edit_url: null
title: "Metodologia"
---

# Introdu√ß√£o

Aqui ser√° apresentada a metodologia do que foi feito durante a terceira Sprint de desenvolvimento da solu√ß√£o com o sistema do Turtlebot, nesta documenta√ß√£o ser√£o abordados os temas relacionados ao sistema `LiDAR` e seguran√ßa, al√©m do sistema de aquisi√ß√£o de imagens do rob√¥ em tempo real.

:::tip Lembre-se
O `LiDAR` no TurtleBot 3 √© um sensor de varredura a laser que mede dist√¢ncias at√© objetos em seu entorno. Ele emite pulsos de laser e calcula o tempo que cada pulso leva para refletir de volta ao sensor, permitindo a cria√ß√£o de um mapa 2D preciso do ambiente.
:::

Segue abaixo as etapas executadas para a realiza√ß√£o da terceira Sprint.

## Tecnologias

Durante est√° sprint, ser√£o utilizadas as seguintes tecnologias;

### üöÄ LiDAR
O LiDAR (Light Detection and Ranging) √© um sensor que mede dist√¢ncias at√© objetos em seu entorno. Ele funciona emitindo pulsos de laser e calculando o tempo que cada pulso leva para refletir de volta ao sensor, permitindo a cria√ß√£o de um mapa 2D preciso do ambiente.

**Principais Fun√ß√µes do LiDAR no TurtleBot 3:**

- **Navega√ß√£o Aut√¥noma:** Ajuda o TurtleBot 3 a navegar de forma aut√¥noma, evitando obst√°culos e planejando rotas seguras.
- **Detec√ß√£o de Obst√°culos:** Detecta obst√°culos ao redor do rob√¥, permitindo rea√ß√µes a mudan√ßas no ambiente e evitando colis√µes.

:::note 
O `LiDAR` pode ser utilizado de outras maneiras tamb√©m. Todavia at√© ent√£o usaremos o mesmo em nossa solu√ß√£o apenas para as fun√ß√µes descritas acima. Se quiser informa√ß√µes adicionais do que o LiDAR √© capaz de realizar, recomendo ler este [artigo](https://www.faro.com/en/Resource-Library/Article/What-is-Lidar#:~:text=Lidar%20technology%20is%20an%20ideal,models%20and%20map%20digital%20elevation.).
:::

### üì∏ OpenCV
OpenCV (Open Source Computer Vision Library) √© uma biblioteca de vis√£o computacional de c√≥digo aberto que fornece uma ampla gama de ferramentas para processamento de imagem e v√≠deo.

**Principais Fun√ß√µes do OpenCV:**

- **Processamento de Imagem:** Filtragem, transforma√ß√£o, segmenta√ß√£o e an√°lise das imagens adquiridas pelo rob√¥.
- **Detec√ß√£o de Objetos:** Algoritmos para reconhecimento e rastreamento de objetos, no caso do projeto ser√° utilizada a detec√ß√£o de entupimento nos canos.
- **Machine Learning:** Integra√ß√£o com modelos de aprendizado de m√°quina para tarefas de vis√£o computacional.

### üé• C√¢mera do Dobot Magician
A c√¢mera do Dobot Magician √© usada para captura de imagens e v√≠deos, permitindo a intera√ß√£o visual com o ambiente.

**Principais Fun√ß√µes da C√¢mera do Dobot Magician:**

- **Captura de Imagem:** Obten√ß√£o de imagens est√°ticas do ambiente para an√°lise.
- **V√≠deo em Tempo Real:** Transmiss√£o de v√≠deo ao vivo para monitoramento e controle.
- **Integra√ß√£o com Vis√£o Computacional:** Utilizada junto com bibliotecas como OpenCV para detec√ß√£o e reconhecimento de objetos.

### üåê Streamlit
Streamlit √© uma biblioteca de c√≥digo aberto para cria√ß√£o de aplicativos web interativos em Python, facilitando a visualiza√ß√£o de dados e a cria√ß√£o de interfaces de usu√°rio.

**Principais Fun√ß√µes do Streamlit:**

- **Cria√ß√£o de Interfaces de Usu√°rio:** Ferramentas simples para construir interfaces de usu√°rio interativas.
- **Visualiza√ß√£o de Dados:** Integra√ß√£o f√°cil com bibliotecas de visualiza√ß√£o como Matplotlib, Plotly e Altair.
- **Desenvolvimento R√°pido:** Facilita o desenvolvimento r√°pido de prot√≥tipos e aplicativos.
- **Interatividade:** Permite a cria√ß√£o de widgets interativos para manipula√ß√£o de dados em tempo real.

:::info Nota
Como ainda na Sprint 3, o projeto n√£o foi conclu√≠do, as tecnologias ainda podem ser mudadas posteriormente.
:::

### T√≥picos Utilizados Durante a Sprint 3

Seguindo o mesmo conceito de t√≥picos citados durante a [metodologia na Sprint 2](../../sprint-2/Documenta√ß√£o/Metodologia.md#t√≥picos), apresentamos o principal t√≥pico utilizado nesta Sprint para capacitar o rob√¥ com a tecnologia `LiDAR`.

#### T√≥pico Principal

**/scan**: O t√≥pico `scan` desempenha um papel crucial no funcionamento do rob√¥ equipado com `LiDAR`. Atrav√©s deste t√≥pico, o `LiDAR` envia os dados para o sistema ROS (Robot Operating System). Esses dados s√£o indispens√°veis para o controle da movimenta√ß√£o do rob√¥, permitindo que ele pare automaticamente ao detectar obst√°culos.

:::info Nota
üìù Para mais detalhes sobre a configura√ß√£o do `LiDAR` e como o t√≥pico `/scan` √© implementado no ROS, consulte a [documenta√ß√£o t√©cnica](../../sprint-2/Documenta√ß√£o/Metodologia.md#t√≥picos-e-n√≥s).
:::

---

## Cria√ß√£o dos Novos Sistemas

A seguir, discutiremos como os novos sistemas de [`LiDAR`](#üöÄ-lidar) e [processamento de imagens](#üì∏-opencv) foram integrados ao projeto, juntamente com as principais partes do c√≥digo relacionadas a esses sistemas.

:::info Nota
Este √© um resumo das modifica√ß√µes realizadas. Para acessar o c√≥digo fonte completo, visite o [GitHub do projeto](https://github.com/Inteli-College/2024-1B-T08-EC06-G04).
:::

### Adi√ß√£o do LiDAR no C√≥digo de Movimenta√ß√£o do Rob√¥

Para integrar o `LiDAR` ao c√≥digo do rob√¥, foram necess√°rias v√°rias modifica√ß√µes importantes. Entre elas, destacam-se:

- **Escuta do T√≥pico `scan`**: O rob√¥ foi configurado para escutar o t√≥pico `scan` a fim de receber dados de dist√¢ncia fornecidos pelo `LiDAR`.
- **Implementa√ß√£o de Ferramenta de Obstru√ß√£o**: Foi desenvolvida uma ferramenta que impede a movimenta√ß√£o do rob√¥ caso a frente esteja obstru√≠da, evitando que ele avance. De forma similar, se a parte traseira estiver obstru√≠da, o rob√¥ n√£o poder√° se mover para tr√°s.


### Bibliotecas referentes ao LiDAR utilizadas

Aqui est√£o as novas bibliotecas que foram integradas ao projeto nesta sprint relacionadas ao LiDAR:

#### LaserScan (sensor_msgs.msg)
A biblioteca `LaserScan` √© utilizada para processar os dados adquiridos atrav√©s da escuta do t√≥pico `scan`. Esta biblioteca √© essencial para interpretar as leituras do `LiDAR` e garantir que os dados de dist√¢ncia sejam corretamente compreendidos pelo sistema.

#### qos_profile_sensor_data (rclpy.qos)
A biblioteca `qos_profile_sensor_data` foi usada para adicionar Quality of Service (QOS) ao t√≥pico do ROS2. Isso garante a qualidade na transmiss√£o dos dados sensoriais, permitindo que o rob√¥ reaja rapidamente √†s mudan√ßas no ambiente.

:::info Nota
Todas as bibliotecas apresentadas na [**Sprint 2**](../../sprint-2/Documenta√ß√£o/Metodologia.md#bibliotecas-usadas) continuam sendo utilizadas nesta sprint.
:::

Segue abaixo o import exato das bibliotecas em python:

```python
from rclpy.qos import qos_profile_sensor_data
from sensor_msgs.msg import LaserScan
```

:::tip
Nenhuma destas bibliotecas √© necess√°rio utilizar o pip para baixar. Ambas **ja fazem parte** do ambiente de execu√ß√£o do ROS2
:::

### C√≥digo atualizado referente a movimenta√ß√£o do rob√¥

Abaixo est√° o c√≥digo atualizado de movimenta√ß√£o do rob√¥ com a integra√ß√£o do LiDAR. As novas funcionalidades introduzidas ser√£o discutidas detalhadamente a seguir, juntamente com a l√≥gica por tr√°s de sua implementa√ß√£o.

:::info Nota
Se seu rob√¥ n√£o √© capaz de interagir com o LiDAR, √© poss√≠vel seguir utilizando o c√≥digo desenvolvido na [Sprint 2](https://github.com/Inteli-College/2024-1B-T08-EC06-G04/tree/0.2.0) do rob√¥, por√©m **limitado** nas fun√ß√µes apresentadas naquela Sprint.
:::

```python
Codigo LIDAR :D
```

### Adi√ß√£o do Streamlit e Processamento de Imagens

Para proporcionar uma melhor visualiza√ß√£o do rob√¥, al√©m de um sistema de controle mais otimizado e com uma UX aprimorada, desenvolvemos uma interface de usu√°rio mais intuitiva e direta. Esta nova interface inclui:

- **Visualiza√ß√£o em Tempo Real**: Uma c√¢mera acoplada ao rob√¥ permite gravar e transmitir em tempo real o que o rob√¥ est√° fazendo, oferecendo uma vis√£o completa das opera√ß√µes.
- **Bot√µes de Controle Intuitivos**: Foram adicionados bot√µes de controle mais intuitivos e f√°ceis de usar, facilitando a intera√ß√£o e o controle do rob√¥.

A interface foi desenvolvida utilizando o Streamlit, que oferece uma plataforma eficiente para criar aplica√ß√µes web interativas com Python.

### Bibliotecas Referentes ao Streamlit

Abaixo est√£o listadas as bibliotecas utilizadas para o funcionamento do Streamlit e para o processamento de imagens em tempo real:

- **cv2**: Utilizada para o processamento de imagens em tempo real.
- **base64**: Utilizada para codifica√ß√£o e decodifica√ß√£o de imagens.
- **numpy (np)**: Utilizada para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
- **streamlit (st)**: Utilizada para criar a interface web interativa.
- **PIL (Image)**: Utilizada para manipula√ß√£o de imagens.
- **io**: Utilizada para opera√ß√µes de entrada e sa√≠da.

#### C√≥digo de Importa√ß√£o

Segue abaixo o c√≥digo de importa√ß√£o dessas bibliotecas em Python:

```python
import cv2
import base64
import numpy as np
import streamlit as st
from PIL import Image
import io
```

:::info Nota
Exceto pelas bibliotecas `base64` e `io`, todas as outras bibliotecas mencionadas precisam ser instaladas utilizando o gerenciador de pacotes do Python, `pip`. As instru√ß√µes detalhadas para a instala√ß√£o est√£o dispon√≠veis no guia de execu√ß√£o.
:::

### C√≥digo referente a interface visual e processamento de imagens

Os c√≥digos abaixo s√£o referentes a tanto a interface visual quanto ao processamento das imagens adquiridas pela c√¢mera do rob√¥. Afim de deixar mais claro como o mesmo foi executado e como pode ser alterado afim de abranger todas as necessidades.

:::warning
Qualquer altera√ß√£o no c√≥digo pode causar falhas ou mal-funcionamento do rob√¥, altere o mesmo em seu pr√≥prio risco.
:::

O c√≥digo abaixo √© utilizado dentro do rob√¥, onde o mesmo serve para passar as informa√ß√µes da webcam para o ambiente do ROS2 que contem o c√≥digo do Streamlit na m√°quina pessoal.

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import cv2
import base64

class Talker(Node):
    def __init__(self):
        super().__init__('talker')
        self.publisher_ = self.create_publisher(String, 'chatter', 10)
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            self.get_logger().error("Erro: N√£o foi poss√≠vel acessar a webcam.")
            return
        self.cap.set(cv2.CAP_PROP_FPS, 30)  # Configura a c√¢mera para 60 FPS, se suportado
        timer_period = 0.0167  # aproximadamente 0.0167 segundos (60 FPS)
        self.timer = self.create_timer(timer_period, self.timer_callback)

    def timer_callback(self):
        ret, frame = self.cap.read()
        if ret:
            _, buffer = cv2.imencode('.jpg', frame)
            jpg_as_text = base64.b64encode(buffer).decode('utf-8')
            msg = String()
            msg.data = jpg_as_text
            self.publisher_.publish(msg)
            self.get_logger().info('Publishing image as base64 string')
        else:
            self.get_logger().error('Could not read image from webcam')

    def destroy_node(self):
        self.cap.release()
        super().destroy_node()

def main(args=None):
    rclpy.init(args=args)
    node = Talker()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

Abaixo ser√° explicado melhor o c√≥digo, suas classes e m√©todos.